<h1>Awesome-LLM-VLM-Foundation-Models</h1>
<p>Awesome curated list of LLM, VLM and other Foundation Models</p>

<div style="overflow-x:auto;">
<table>
  <thead>
    <tr>
      <th>No.</th>
      <th>Model</th>
      <th>Year</th>
      <th>Company</th>
      <th>Size & Context Window</th>
      <th>Best For / Strengths</th>
      <th>Access & Cost</th>
      <th>Link</th>
    </tr>
  </thead>
  <tbody>
    <tr><td>1</td><td>GPT‑4.5 “Orion”</td><td>2025-02</td><td>OpenAI</td><td>~12 T params / 128K tokens</td><td>Nuanced conversation, creative writing, lower hallucinations</td><td>ChatGPT Pro/Premium $200 /mo; API: $75/1M in, $150/1M out</td><td>OpenAI</td></tr>
    <tr><td>2</td><td>GPT‑4.1</td><td>2025-04</td><td>OpenAI</td><td>Large / 1M tokens</td><td>Long-context docs, coding, vision, low latency</td><td>API: input $2, output $8 per 1M tokens; Mini variant cheaper</td><td>OpenAI</td></tr>
    <tr><td>3</td><td>GPT‑4o (“Omni”)</td><td>2024-05</td><td>OpenAI</td><td>Multimodal / 128K tokens</td><td>Text+image+audio+voice; fast & free-tier use</td><td>Free-tier in ChatGPT; API: $2.50/1M in, $10/1M out</td><td>OpenAI</td></tr>
    <tr><td>4</td><td>GPT‑4o mini</td><td>2024-07</td><td>OpenAI</td><td>~8 B params / 128K tokens</td><td>Cost-effective multimodal</td><td>ChatGPT replacement; API: $0.15/1M in, $0.60/1M out</td><td>OpenAI</td></tr>
    <tr><td>5</td><td>o4‑mini‑high / o4‑mini</td><td>2025-04</td><td>OpenAI</td><td>Compact reasoning / multimodal</td><td>STEM, coding, fast reasoning with vision</td><td>API: input $1.10, output $4.40 per 1M tokens</td><td>OpenAI</td></tr>
    <tr><td>6</td><td>o3‑mini‑high / o3‑mini</td><td>2024</td><td>OpenAI</td><td>Small reasoning models</td><td>Technical/scientific reasoning on a budget</td><td>API: same pricing as o3 & mini models</td><td>OpenAI</td></tr>
    <tr><td>7</td><td>Llama 4 Maverick</td><td>2025</td><td>Meta AI</td><td>Large Mixture‑of‑Experts</td><td>Coding, reasoning; GPT‑4o‑level</td><td>Open weights (restricted use)</td><td>Meta/HF</td></tr>
    <tr><td>8</td><td>Llama 4 Scout</td><td>2025</td><td>Meta AI</td><td>Small (fits 1 A100/H100) / 10M tokens</td><td>Generalist, long context small model</td><td>Open weights</td><td>Meta/HF</td></tr>
    <tr><td>9</td><td>Llama 3.1 405B</td><td>2024</td><td>Meta AI</td><td>405 B params / 128K tokens</td><td>Research, long-context, coding</td><td>Open source</td><td>Meta/HF</td></tr>
    <tr><td>10</td><td>Claude 3.7 Sonnet</td><td>2024-10</td><td>Anthropic</td><td>~175 B params / 200K tokens</td><td>Extended reasoning & coding</td><td>API (paid via Anthropic)</td><td>Anthropic</td></tr>
    <tr><td>11</td><td>Gemini 2.5 Pro</td><td>2024-05</td><td>Google DM</td><td>Undisclosed; multimodal / 1M tokens</td><td>Advanced reasoning, multimodal</td><td>API (paid via Google)</td><td>Google</td></tr>
    <tr><td>12</td><td>Stable LM 2 12B</td><td>2024-04</td><td>Stability AI</td><td>12 B params</td><td>Open model with good benchmarks</td><td>Open source</td><td>Stability</td></tr>
    <tr><td>13</td><td>Qwen 2.5-VL 32B</td><td>2025-03</td><td>Alibaba</td><td>32 B params; multimodal / 128K tokens</td><td>Vision+language tasks</td><td>Open source (Apache 2.0)</td><td>HuggingFace</td></tr>
    <tr><td>14</td><td>Mistral Small 3.1</td><td>2025-03</td><td>Mistral AI</td><td>24 B params; 128K tokens</td><td>Image & doc understanding</td><td>Open source (Apache 2.0)</td><td>Mistral/HF</td></tr>
    <tr><td>15</td><td>Gemma 3 (27B)</td><td>2025-03</td><td>Google DM</td><td>27 B params</td><td>One-GPU efficient model</td><td>Open source</td><td>DeepMind</td></tr>
    <tr><td>16</td><td>Fox-1 1.6B Instruct</td><td>2024-11</td><td>Fox-1 project</td><td>1.6 B params</td><td>Instruction-following small LLM, conversational</td><td>Open source (Apache 2.0)</td><td>arXiv</td></tr>
  </tbody>
</table>
</div>

## Foundation Models Leaderboards (2025)

This is a curated list of new and up-to-date leaderboards for Large Language Models (LLMs), Vision-Language Models (VLMs), and multimodal models, published or updated in 2025. Each leaderboard provides performance metrics, rankings, and comparisons for state-of-the-art foundation models.

1. **[LLM Leaderboard 2025 - llm-stats.com](https://llm-stats.com)**  
   Comprehensive leaderboard for LLMs with performance metrics and benchmark data. Includes interactive analysis tools to compare models like GPT-4o, Llama, o1, Gemini, and Claude based on context window, speed, and price. 

2. **[Open LLM Leaderboard - Hugging Face](https://huggingface.co/open-llm-leaderboard)**  
   Evaluates open-source LLMs using benchmarks like IFEval, BBH, and MATH. Features real-time filtering and analysis of models, with community voting and comprehensive results.

3. **[LLM Leaderboard 2025 - Vellum](https://www.vellum.ai/llm-leaderboard)**  
   Compares capabilities, price, and context window for leading commercial and open-source LLMs. Features 2025 benchmark data from model providers and independent evaluations, focusing on non-saturated benchmarks (excluding MMLU). 

4. **[LLM Leaderboard - Artificial Analysis](https://artificialanalysis.ai)**  
   Ranks over 100 LLMs across metrics like intelligence, price, performance, speed (tokens per second), and context window. Provides detailed comparisons for models from OpenAI, Google, DeepSeek, Alibaba Cloud and others. 

5. **[SEAL LLM Leaderboards](https://scale.com/leaderboards)**  
   Expert-driven, private evaluations of LLMs across domains like coding and instruction following. Uses curated datasets to prevent overfitting and ensure high-complexity evaluations. 

6. **[Open VLM Leaderboard - Hugging Face](https://huggingface.co/spaces/opencompass/open_vlm_leaderboard)**  
   Ranks open-source VLMs using 23 multimodal benchmarks (e.g., MMBench_V11, MathVista). Evaluates models like GPT-4v, Gemini, QwenVLPlus, and LLaVA on image-text tasks.

7. **[Zero-Shot Video Question Answer on Video-MME](https://paperswithcode.com/sota/zero-shot-video-question-answer-on-video-mme-1)**  
   This task present the results of Zeroshot Question Answer results on TGIF-QA dataset for LLM powered Video Conversational Models.

## Frameworks and Tools for LLMs, VLMs, and Foundation Models (2025)

This list highlights key frameworks and tools for developing, deploying, and managing Large Language Models (LLMs), Vision-Language Models (VLMs), and foundation models.

1. **[LangChain](https://www.langchain.com)**  
   A versatile framework for building LLM-powered applications. It simplifies prompt chaining, memory management, and integration with external data sources like vector databases and APIs. Used for chatbots, RAG systems, and agent-based workflows.

2. **[LlamaIndex](https://www.llamaindex.ai)**  
   A data framework designed for connecting LLMs with custom data sources. It excels in data ingestion, indexing, and retrieval for RAG applications, enabling semantic search and context-aware querying. Ideal for document analysis and knowledge base systems.

3. **[n8n](https://n8n.io)**  
   An open-source, low-code workflow automation platform. It integrates LLMs with external tools and APIs to automate tasks like data processing or chatbot responses. Used for building scalable AI-driven workflows with minimal coding.

4. **[DSPy](https://dspy.ai)**  
   A framework for programming foundation models by defining tasks rather than crafting prompts. It optimizes pipelines for LLMs using modular components, improving performance in tasks like reasoning and text generation. Suited for developers seeking maintainable codebases.

5. **[Haystack](https://haystack.deepset.ai)**  
   An open-source framework for building LLM-powered search and RAG applications. It supports semantic search, document retrieval, and question answering, with integrations for Hugging Face, OpenAI, and vector stores like Pinecone. Used for enterprise search systems.

6. **[MLflow](https://mlflow.org)**  
   An open-source platform for managing the machine learning lifecycle, including LLMs and VLMs. It supports experiment tracking, model versioning, and deployment, with integrations for LangChain, LlamaIndex, and DSPy. Ideal for reproducible AI workflows.

7. **[Hugging Face Transformers](https://huggingface.co/docs/transformers)**  
   A comprehensive library for training, fine-tuning, and deploying LLMs and VLMs. It supports models like BERT, GPT, and CLIP, with tools for NLP, computer vision, and multimodal tasks. Used for research and production-grade AI applications.

8. **[Ollama](https://ollama.com)**  
   A lightweight framework for running LLMs locally. It provides a simple API and supports models like Llama 3 and Gemma, enabling developers to build and test AI applications on personal hardware. Perfect for local AI development and prototyping.

9. **[AutoGen](https://microsoft.github.io/autogen)**  
   A Python-based framework for creating multi-agent LLM systems. It enables agents to collaborate on tasks like data retrieval and code execution, enhancing complex workflows. Used for building autonomous AI agents and research.

10. **[Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel)**  
   A Microsoft-developed SDK for integrating LLMs into applications. It supports orchestration of AI tasks, memory management, and plugins for connecting to external tools. Used for building scalable AI agents in Python, C#, and Java.

11. **[DeepEval](https://www.deepeval.com)**  
   A testing framework for evaluating LLM applications. It offers over 14 research-backed metrics to assess RAG pipelines and safety risks, integrating with frameworks like LangChain and LlamaIndex. Used for quality assurance in AI development.

12. **[Flowise](https://flowiseai.com)**  
   An open-source, low-code platform for building LLM applications. It features a drag-and-drop interface and integrates with LangChain and LlamaIndex, making it accessible for non-coders to create chatbots and RAG systems.

13. **[Langflow](https://www.langflow.io)**  
   A visual framework for building multi-agent and RAG applications with LLMs. It offers a drag-and-drop interface and supports cloud or self-hosted deployment. Used for rapid prototyping of AI workflows.

14. **[CrewAI](https://www.crewai.com)**  
   A framework for orchestrating collaborative AI agents powered by LLMs. It simplifies task delegation and agent communication, built on LangChain. Used for automating complex workflows like research or customer support.

15. **[OpenLLM](https://bento.cloud/openllm)**  
   A platform for deploying and managing open-source LLMs. It integrates with LlamaIndex, LangChain, and Hugging Face, offering scalable solutions for chat, reasoning, and coding tasks. Used for production-grade AI deployments.


